{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Triplet visualizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Install the required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio\n",
    "!pip install markdown2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Import the required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import random\n",
    "import markdown2\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Import the functions needed for the GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix LaTeX formatting in a string\n",
    "def fix_latex_formatting(text):\n",
    "    pattern_math_mode = r'\\((\\\\[a-zA-Z]+(?:\\{[^\\}]*\\})?)\\)'\n",
    "    pattern_text_subscript = r'\\{([a-zA-Z]+)\\}'\n",
    "\n",
    "# Function to replace math mode patterns\n",
    "    def replace_math_mode(match):\n",
    "        return f'\\\\\\\\({match.group(1)}\\\\\\\\)'\n",
    "\n",
    "# Function to replace textual subscripts\n",
    "    def replace_text_subscript(match):\n",
    "        return f'{{\\\\text{{{match.group(1)}}}}}'\n",
    "\n",
    "# Replace all found patterns in the text\n",
    "    text = re.sub(pattern_math_mode, replace_math_mode, text)\n",
    "    text = re.sub(pattern_text_subscript, replace_text_subscript, text)\n",
    "    return text\n",
    "\n",
    "# Function to fix LaTeX formatting in a dictionary\n",
    "def fix_latex_in_dict(input_dict):\n",
    "    for key, value in input_dict.items():\n",
    "        if isinstance(value, str):\n",
    "            input_dict[key] = fix_latex_formatting(value)\n",
    "        elif isinstance(value, dict):\n",
    "            fix_latex_in_dict(value)\n",
    "    return input_dict\n",
    "\n",
    "# Function to read a JSONL file\n",
    "def read_jsonl_file(filepath):\n",
    "    global feedback_data, current_jsonl_data\n",
    "    current_jsonl_data = []\n",
    "    feedback_data = {}\n",
    "    #entries = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            if not line.strip():  # Skip empty lines\n",
    "                print(f\"Line {line_number} is empty or whitespace.\")\n",
    "                continue\n",
    "            try:\n",
    "                json_line = json.loads(line)\n",
    "                for j in json_line:\n",
    "                    #print(j)\n",
    "\n",
    "                    current_jsonl_data.append(j)\n",
    "                    feedback_data[j] = None\n",
    "                    #print(f\"Line {line_number}: {json_line}\")\n",
    "                    #print(type(json_line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error on line {line_number}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return None, current_jsonl_data\n",
    "\n",
    "# Function to get random entries from a list of entries, and convert markdown to HTML\n",
    "def get_random_entries(entries, n):\n",
    "    n = int(n)\n",
    "    if len(entries) < n:\n",
    "        return f\"Requested number of entries ({n}) exceeds the available entries ({len(entries)}).\", None\n",
    "    \n",
    "    print(f\"Entries has type : {type(entries)}\")\n",
    "    random_entries = random.sample(entries, n)\n",
    "    \n",
    "    # Convert markdown to HTML\n",
    "    converted_entries = []\n",
    "    for entry in random_entries:\n",
    "        if isinstance(entry, dict):\n",
    "            converted_entry = {\n",
    "                \"instruction\": markdown2.markdown(entry[\"instruction\"]),\n",
    "                \"input\": markdown2.markdown(entry[\"input\"]),\n",
    "                \"output\": markdown2.markdown(entry[\"output\"])\n",
    "            }\n",
    "            converted_entries.append(converted_entry)\n",
    "        else:\n",
    "            var = rf\"{entry}\"\n",
    "            #var = var.replace('\\\\', '\\\\\\\\')\n",
    "            var_dict = json.loads(var)\n",
    "            converted_entry = {\n",
    "                \"instruction\": markdown2.markdown(var_dict[\"instruction\"]),\n",
    "                \"input\": markdown2.markdown(var_dict[\"input\"]),\n",
    "                \"output\": markdown2.markdown(var_dict[\"output\"])\n",
    "            }\n",
    "            converted_entries.append(converted_entry)\n",
    "    return None, converted_entries\n",
    "\n",
    "# Function to interface with the Gradio interface\n",
    "def interface(file, n):\n",
    "    error, entries = read_jsonl_file(file)\n",
    "    if error:\n",
    "        return error\n",
    "    error, random_entries = get_random_entries(entries, n)\n",
    "    if error:\n",
    "        return error\n",
    "    return random_entries\n",
    "\n",
    "\n",
    "# Function to update the output\n",
    "def update_output(file, n):\n",
    "    global feedback_data\n",
    "\n",
    "    if file is None:\n",
    "        return \"Please upload a file.\"\n",
    "    if n < 1:\n",
    "        return \"Please enter a valid number of entries (greater than 0).\"\n",
    "\n",
    "    entries_html = interface(file, n)\n",
    "    if isinstance(entries_html, str):  # If an error message is returned\n",
    "        return entries_html\n",
    "    else:\n",
    "        formatted_entries = []\n",
    "        for entry in entries_html:\n",
    "\n",
    "            entry = fix_latex_in_dict(entry)\n",
    "            print(entry)\n",
    "            print(\"#\"*100)\n",
    "            print(type(entry))\n",
    "            formatted_entry = \"<div><strong>Instruction:</strong> \" + entry[\"instruction\"] + \\\n",
    "                              \"<strong>Input:</strong> \" + entry[\"input\"] + \\\n",
    "                              \"<strong>Output:</strong> \" + entry[\"output\"] + \"</div><hr>\" + \\\n",
    "                              \"<button onclick='feedback(\\\"{entry_id}\\\", \\\"thumbs_up\\\")'>üëç</button>\" + \\\n",
    "                              \"<button onclick='feedback(\\\"{entry_id}\\\", \\\"thumbs_down\\\")'>üëé</button>\"\n",
    "            formatted_entries.append(formatted_entry)\n",
    "        \n",
    "        # Join entries and add the MathJax script\n",
    "        all_entries_html = \"<br>\".join(formatted_entries)\n",
    "        html_with_mathjax = all_entries_html + \"\"\"\n",
    "        <script type=\"text/javascript\" async\n",
    "        src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js\">\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        return html_with_mathjax or \"No entries found.\"\n",
    "\n",
    "def handle_feedback(entry_id, feedback_type):\n",
    "    global feedback_data\n",
    "    feedback_data[entry_id] = feedback_type\n",
    "    return \"Feedback received!\"\n",
    "\n",
    "def download_updated_jsonl():\n",
    "    global feedback_data, current_jsonl_data\n",
    "    updated_jsonl = [entry for entry_id, entry in enumerate(current_jsonl_data) if feedback_data.get(f\"entry_{entry_id}\") != \"thumbs_down\"]\n",
    "    \n",
    "    jsonl_str = \"\\n\".join([json.dumps(entry) for entry in updated_jsonl])\n",
    "    return io.BytesIO(jsonl_str.encode()), \"updated_file.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create the GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## JSONL File Processor\")\n",
    "    gr.Markdown(\"Upload a JSONL file and display a specified number of random entries from the file.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        file_input = gr.File(label=\"Upload JSONL file\")\n",
    "        n_input = gr.Number(label=\"Number of Entries\", value=1, step=1, \n",
    "                            info=\"Enter the number of random entries to display\")\n",
    "        submit_button = gr.Button(\"Show Random Entries\")\n",
    "        feedback_button = gr.Button(\"Submit Feedback\")\n",
    "        download_button = gr.Button(\"Download Feedback-Based JSON\")\n",
    "        \n",
    "    output = gr.HTML(label=\"Random Entries Display\")\n",
    "\n",
    "    submit_button.click(fn=update_output, inputs=[file_input, n_input], outputs=output)\n",
    "\n",
    "    #feedback_button.click(fn=handle_feedback, inputs=[\"entry_id\", \"feedback_type\"], outputs=\"text\")\n",
    "    download_button.click(fn=download_updated_jsonl, inputs=[], outputs=gr.File(label=\"Download Updated JSONL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Launch!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GUI will open below and provide a link to open in a new tab in your browser. Click the link and in the browser you can now upload the file in the attachments `merged_file_xl.jsonl` and visualize the triplets. You can either sample one triplet at a time or change the number of triplets to sample at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://80a6c2a4e7f1378292.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://80a6c2a4e7f1378292.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/queueing.py\", line 427, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/route_utils.py\", line 234, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/blocks.py\", line 1487, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/utils.py\", line 665, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 105, in update_output\n",
      "    entries_html = interface(file, n)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 87, in interface\n",
      "    error, entries = read_jsonl_file(file)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 45, in read_jsonl_file\n",
      "    feedback_data[j] = None\n",
      "    ~~~~~~~~~~~~~^^^\n",
      "TypeError: unhashable type: 'dict'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/queueing.py\", line 427, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/route_utils.py\", line 234, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/blocks.py\", line 1487, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/utils.py\", line 665, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 105, in update_output\n",
      "    entries_html = interface(file, n)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 87, in interface\n",
      "    error, entries = read_jsonl_file(file)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/jx9cxfmn6yxbsb49_0l97pk40000gn/T/ipykernel_22702/573756449.py\", line 45, in read_jsonl_file\n",
      "    feedback_data[j] = None\n",
      "    ~~~~~~~~~~~~~^^^\n",
      "TypeError: unhashable type: 'dict'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/queueing.py\", line 472, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/joanvelja/anaconda3/envs/nlp1/lib/python3.11/site-packages/gradio/queueing.py\", line 436, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
